\documentclass[11pt]{letter}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{color}
\usepackage{parskip}
\usepackage{comment}
\usepackage{mathpazo}
\usepackage[utf8]{inputenc}

\usepackage[margin=1in]{geometry}
\usepackage{setspace}

\onehalfspacing

\newcommand\qa{\begin{center}\line(1,0){250}\end{center}\begin{quote}\begin{em}}
\newcommand\qb{\end{em}\begin{center}\line(1,0){250}\end{center}\end{quote}}
\newcommand{\bx}{\boldsymbol {x}}
\newcommand{\bs}{\boldsymbol {s}}
\newcommand{\bt}{\boldsymbol {t}}
\newcommand{\bc}{\boldsymbol {c}}
\newcommand{\eps}{\varepsilon}
\newcommand{\todo}[1]{ {\color{red} #1 }}

\begin{document}

\signature{Jeremy Hoskins\\
Manas Rachh}

\address{Jeremy Hoskins (Yale University)\\
jeremy.hoskins@yale.edu\\
\vspace{.02in}\\
Manas Rachh (Flatiron Institute)\\
mrachh@flatironinstitute.org}


\begin{letter}{Editorial Office\\
Journal of Computational Physics - X}

\opening{Dear Editor:}



The following document contains a response to the comments made by the
reviewers after reading our manuscript \emph{On the discretization of Laplace's equation with Neumann boundary conditions on polygonal domains}.
In short, we have made revisions to the paper, namely:


Below are the reviews reports indented and in italics, interlaced with
our responses.

\qa
Reviewer \#1:
This manuscript extends a recent line of work on handling the singularities in the density of the standard boundary integral equation formulation of Laplace?s equation that arise at the corners of polygonal domains, through the use of specialized, high-order quadratures, which are computed using analytic expansions of the density. Previous work in this direction has difficulties directly applying this strategy to Neumann problems, since the singularities are significantly worse here than in the Dirichlet case. The current work makes the incredibly interesting observation that one can instead use the adjoint of a discretization to the Dirichlet problem to obtain a solution that is accurate in a weak sense. Furthermore, pointwise accuracy in a region arbitrarily close to a corner can be obtained through a novel local refinement process. The relevant theory for justifying both that this approach yields a density that can be accurately interpolated away from the corners and that the refinement process can be done in a completely local manner is developed. Furthermore, the approach is illustrated through exceptionally thorough and impressive numerical results.

In my opinion, this paper certainly should be published, due to the very high quality of the work and good presentation. However, the manuscript in its current state is missing a few details that I believe are of crucial interest to potential readers and is confusing in a few places. I suspect that a couple of these missing details are present elsewhere in the literature, but I still believe that it would be valuable to include them here for the purpose of producing a relatively self-contained work. Furthermore, there are several suspected typos and notational inconsistencies that should be fixed to maximize readability. When these are resolved, I think this will be a very strong paper.

Remarks on content and readability

1) p. 2. The last sentence of the first paragraph mentions that the disadvantage of compression-based approaches to quadrature is cost in 3D. Given that these approaches have already been used in 3D problems, unlike the work in the current paper, I think that as a minimum there should be a couple of brief remarks somewhere about how the method here would extend and scale to 3D.

\qb

\todo{JH}

\qa
2) p. 6. On a first reading, Theorem 6 is not easy to digest. Could you add a few comments to provide some intuition for this result, and also a comment on the connection of the result on an open wedge to the case of polygons? Do we expect the expansions to be exactly the same?

\qb

\todo{JH}



\qa
3) p. 8. I think it is extremely important to explicitly discuss how large we expect K to be in section 4.1.1, especially how it relates to the accuracy a user might desire. I realize the relevant information is likely in [14], but it is of sufficient importance to the current work to make this clear by either stating a result or computational experience.

\qb
\todo{JH}

\qa
4) p. 11. The theory as developed considers only the exterior Neumann problem. I?m guessing a similar duality relationship holds with the interior Neumann problem and the exterior Dirichlet problem, and the procedure carries over straightforwardly (indeed, you consider an interior Neumann problem in the numerical results). For the sake of completeness, could you add a brief remark on whether or not the procedure is exactly the same for the interior Neumann problem, and state if there are any special considerations that are different from the exterior Neumann case?

\qb
\todo{JH}

\qa
5) p. 13. I find the choice of notation in Theorem 8 to be very poor. In particular $A_{0}$ and $f_{0}$ are
used right above in (56) to denote the local problem after the corner has been refined ($A_{0}$ is of size
$P + 2M \times P + 2M$). Then in the statement of the theorem, these variables are used to denote the
analogous variables on just the corner panel of the unrefined problem ($A_{0}$ is of size $P \times P$ ), and then
in the proof of the result these variables are used to refer to the original corner panel as well as the
adjacent panels ($A_{0}$ is of size $P + 2M \times P + 2M$ ). Also, I am not sure why $f_{0}$ is not underlined, since it is a vector. Could you please fix this notation?

\qb
\todo{JH}

\qa
6) p. 19. In the same vein as comment 3, I find the absence of any information on conditioning to be a bit startling, since one of the main appeals of working with boundary integral equations is the ability
to form well-conditioned discretizations. Again, I am aware that this falls squarely into the scope of existing work (again, probably [14]), but find this also sufficiently important to at least summarize in the current work.

\qb
\todo{MR}

\qa
7) p. 19. Even for a problem with 22k dofs, 105 iterations of a Krylov method seems like a lot, especially if the problem is well-conditioned. I can?t help but wonder if this is an artifact of the fact that your FMM tolerance is the same as your iterative method tolerance. If you set the latter to 1e-14 or 1e-13, does the number of iterations decrease drastically?

\qb
\todo{MR}

\qa
8) 
p. 21-22. I find the content of Appendix B difficult to understand for a number of reasons. The motivation for such a result is clear, but I?m not sure I totally understand the conclusion. In particular, you want to show that using the adjoint discretization one can interpolate the density on a panel far from the corner. That makes sense. Your approach to showing this is to use the relation (B.1) to find another equivalent integral equation, which you then show can be solved using existing information accurately.
Is the claim that to actually interpolate the density on such a panel, one would need to solve another Dirichlet problem, and it does NOT suffice to just interpolate the value of ? obtained on the GL nodes when solving the original problem? Please clarify this point.

\qb
\todo{MR}

\qa 
There are these other issues I?m having with it:
(a) On your assumptions about the discretization, 1 and 3 have an easy-to-understand interpretation. It?s unclear to me what 2 is really assuming about the discretization, given that it seems to mostly to be introducing notation. Of course, I can imagine conditions where ?0 is less than the width of some panels, but is there some deeper restriction?
(b) Your assumption that ?0 > 1 and your later statement that the rate at which a polynomial interpolant will converge is C??M is a bit awkward, since these choices are specific for a function
on an interval of length 2.
0
(c) The second paragraph on p. 22 is very unclear to me. I don?t even understand the first sentence as to why k(s,t) would be identically 0 on the same segment as ?([s1,s2]), or what is really even meant by ?segment? here. Furthermore, it is mentioned that k(s, t) when considered as a function of t ? C has a singularity at ?(s). Given the current setup wouldn?t the singularity be at s? I would recommend rewriting this entire paragraph to be more transparent.

\qb
\todo{MR}

\qa
Small fixes and typos:

\qb
\todo{JH}



\qa
Reviewer \#4:
This article is not suitable for JCP. Most of it is Theorem, Lemma, Proposition, Remark. Journal of Computational Physics focuses on computational aspects of physical problems and contributions in mathematical and numerical modeling, rather than numerical analysis. This paper should be submitted to SIAM NUM ANALYS., or IMA J. NUM. ANAL., or Numerische Mathematik.


\qb

\todo{MR}

\qa

The scope of the article completely misses an entire arena of literature in the field, the unified transform (Fokas) method that has attacked the problem at hand in a much cleaner and nicer way in only 12 lines of code. It does not require a discretization with 22,240 points. See the work by Dr. Anthony Charles Lewis Ashton, Matthew J. Colbrook, and Natasha Flyer.

\qb

\todo{MR}

\qa

The method does the simplest of problems, Laplace on a convex domain, that was attacked much earlier and neater in 2001/2003 by Fokas. This paper does not show non-convex polygonal domains or Helmholtz or modified Helmholtz.

\qb

\todo{MR}




We thank the reviewer for their careful reads of our manuscript, and comments 
which have helped significantly improve the quality of the manuscript.
We hope that our revised manuscript based on their suggestions is now
suitable for publication in PAA.


\closing{Sincerely,}

\ps


\end{letter}
\end{document}
